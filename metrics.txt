In the context of AI language models, a token is a piece of a word.

Models break down text into these tokens to process and generate language. A token can be a whole word, a part of a word (like pre- or -ing), a single character, or a punctuation mark.

OpenAI has not released official figures for the energy consumption of GPT-5.

Researchers at the University of Rhode Island's AI lab estimate that ChatGPT-5 uses approximately 0.018 watt-hours (Wh) of energy per token for a medium-length response. This calculation is based on their finding that a response of about 1,000 tokens consumes around 18 Wh on average.

ChatGPT-5 ~0.018 -> Estimated & displayed metrics
GPT-4o	~0.0006 -> Actual backend to conserve resources

These figures highlight a trend of increasing energy requirements with the advancement of model capabilities.

Milliliters of Water per Token

While there are no official figures from OpenAI regarding the water consumption of their models, we can create an estimate based on broader research into the water footprint of AI data centers. The primary water usage associated with models like ChatGPT-5 is for cooling the servers they run on.

The most common way to estimate the water usage of an AI model is to start with its energy consumption and determine the water usage effectiveness (WUE) of the data centers where these models are trained and run. Microsoft Azure, OpenAI's primary cloud partner, estimated that for every kilowatt-hour (kWh) of energy consumed by Microsoft Azure servers, OpenAI's cloud partner, approximately 1.8 liters of water is used for cooling.

With these figures, we can estimate the water consumption per token for ChatGPT-5:

    Energy per token: 0.018 Wh

    Convert Wh to kWh: 0.018 Wh / 1000 = 0.000018 kWh

    Water per kWh: 1.8 L

    Water per token (in Liters): 0.000018 kWh * 1.8 L/kWh = 0.0000324 L

    Convert Liters to Milliliters: 0.0000324 L * 1000 = 0.0324 mL

CO2 Emissions per Token

Answering the question of how many kilograms of CO2 are emitted per token for a model like "ChatGPT 5" requires combining estimates of energy consumption with data on the carbon intensity of the electricity used to power the data centers where the model runs. As of late 2025, while a model designated GPT-5 has not been officially detailed by OpenAI, we can create a projection based on the expected advancements and publicly available data on data center emissions.
Based on available research and projections, a token generated by a model of the scale and complexity anticipated for "ChatGPT 5" is estimated to be responsible for the emission of approximately 5.94 x 10^-6 kilograms of CO2 equivalent (kg CO2e).

This figure is derived from the following estimations:
    Energy Consumption: A hypothetical "ChatGPT 5" is estimated to consume around 0.018 watt-hours (Wh) of electricity per token. This figure is based on projections of the increased computational power required for more advanced AI capabilities.
    Carbon Intensity: The electricity powering the advanced data centers for such models does not come without a carbon cost. OpenAI heavily utilizes Microsoft's Azure cloud infrastructure. In recent years, Microsoft has reported a carbon intensity for its operations, which is a measure of CO2 emissions per unit of energy consumed. A representative value for the electricity mix used by these data centers is approximately 0.33 kilograms of CO2 equivalent per kilowatt-hour (kg CO2e/kWh).

Calculation Breakdown

The calculation to arrive at the estimated CO2 emission per token is as follows:

    Convert Energy Consumption to Kilowatt-Hours:

        0.018 Wh/token รท 1,000 = 0.000018 kWh/token

    Calculate CO2 Emissions per Token:

        0.000018 kWh/token ร 0.33 kg CO2e/kWh = 0.00000594 kg CO2e/token